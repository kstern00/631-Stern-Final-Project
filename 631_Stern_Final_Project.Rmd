---
title: "High School Girls Cross Country Trends"
author: "Kristina Stern"
date: "5/15/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r load-packages, include=FALSE}
library(dplyr)
library(magrittr)
library(knitr)
```

```{r pressure, echo=FALSE, out.width = '100%', fig.align="center"}
knitr::include_graphics("MSHSL075943MSHSL.jpg")
```

## What
My project is about trends in Minnesota girls high school cross country.  I want to show how, on average, the race times have gotten faster every year and that the talent pool has deepened.  I also want to prove that placing well when you are younger does not guarantee success as you age. 

## Why
I've followed cross country and track for almost 20 years now; it is my 'fantasy football' basically.  I've noticed that, over time, the performances have been consistently getting better and I wanted to prove it statistically.  I've also had several heated internet forum discussions regarding girls who are deemed 'prodigies' at a young age and I am looking forward to providing evidence as to why doing well in 9th grade doesn't always translate to doing well in 12th grade. 

## How
In addition to trend fitting, I am going to be making use of subsets to be able to really look at how the data changes within particular groups. I will also be using a data filter to find runners who have appeared more than once in the data set. 

# Body
## Why Cross Country
Cross country is running long distances while not on a track.  Some races are done on various trails while others are done on golf courses.  Minnesota hold their cross country championships on a golf course, which has remained at the same place since 1992.  Boys cross country state meets started in 1943 while girls meets started in 1975. Approaches to Coaching philosophies, gear, nutrition and exposure to cross country on a bigger stage have all shifted over the years, which also contributes to the changing of running averages.  I chose cross country over track because there is more data and I chose girls cross country because girls are often overlooked when people talk about MSHSL history. Women's sports are often marginalized and not taken as seriously as men's sports, with Title IX still undergoing attacks 50 years later.  I wanted to demonstrate the huge strides women (and girls) have taken over the years in the sport. 

## The Data
I used the data found on [Raceberry Jam](https://www.raceberryjam.com/indexcc.html).  This site has complete data from 1991 in a semi-usable format.  There is older data out there but it isn't formatted as well and is missing various data points, such as times.  I copied and pasted it into Notepad++ and used regular expressions to re-format it into something more usable. I replaced all double white space with a comma (to preserve names in one column), replaced any double commas with a single comma (sometimes more than once) and then saved it to a CSV file.  The original data looked something like this - 

    1        Megan Hasz, 11                5:15.2    13:40.9    Alexandria           
    2        Bethany Hasz, 11              5:15.4    13:44.4    Alexandria           
    3        Tess Misgen, 10               5:23.3    14:13.5    Shakopee             
    4     1  Emma Benner, 11               5:25.8    14:13.6    Forest Lake          
    5        Emily Covert, 8               5:24.8    14:15.0    Minneapolis Washburn 
    6     2  Rachel King, 12               5:26.5    14:15.1    St. Michael-Albertvil 
    7     3  Anna French, 12               5:17.6    14:15.9    Wayzata              
    8     4  Annika Lerdall, 10            5:39.7    14:18.4    Wayzata              
    9     5  Emily Betz, 12                5:27.0    14:19.0    East Ridge      
    
The first column is the place, the second column is the team place, followed by name, grade, average time, overall time and school.  I wasn't interested in the team place or the average time so I needed to delete those. I created a macro to delete all the cells where there was a team place and shift the remaining cells in that row over.  That made it easier to just delete the average time column once everything was aligned. For all the times prior to 2015 I had to convert them to their equivalent 5k times using this equation: 

$$
t2 = t1 * (\frac{d2}{d1})^{1.06}
$$

There was some trouble with this since the formatting wasn't always consistent.  Out of the 4617 lines of data, I had to change about 20 by hand.  I originally added an index to the data but found I didn't need it so I removed it from the final dataset. 

# Using the data in R
To use the data in R, I used the readr library and then imported the data into an R table using instructions from [Statology](https://www.statology.org/import-csv-into-r/). 
```{r, echo=FALSE}
library(readr)

xc_data <-read_csv("XC.csv")

```

First, a check that the data imported correctly.  
```{r, echo=FALSE}
head(xc_data)

```


How many runners from each grade there were overall:
```{r, echo=FALSE}
table(xc_data$Grade)

```

A plot of the above table:
```{r, echo=FALSE, fig.align='left'}
barplot(table(xc_data$Grade), main = "Distribution of Grades", xlab = "Grade", ylab = "Number of Runners")

```




I wanted to look at how times had progressed from different decades.  I chose 1995 and 2015 for this example.  Below is the density plots of the times of those two years. 
```{r, echo=FALSE, fig.align='left'}
times_1995 <- subset(xc_data, xc_data$Year == 1995)
times_2015 <- subset(xc_data, xc_data$Year == 2015)
plot(density(times_1995$Time), main = "Density Plot of Times", col = 'red', xlab = "Time (min)", ylim=c(0,.4))
lines(density(times_2015$Time), col = 'blue')
legend(24, .4, legend=c("1995", "2015"),
       col=c("red", "blue"), lty=1:2, cex=0.8)

```
The average time and standard deviation from 1995: 
```{r, echo=FALSE}
mean(times_1995$Time)
sd(times_1995$Time)

```
The average time and standard deviation from 2015: 
```{r, echo=FALSE}
mean(times_2015$Time)
sd(times_2015$Time)

```
This shows that not only were times faster in 2015 but the spread was much tighter. 

Let's look at the data for a few specific places. I wanted to include 150th place in my plots but the race didn't have as many participants the first decade.  

First place:
```{r, echo=FALSE}
place_1 <- subset(xc_data, xc_data$Place == 1)
place_10 <- subset(xc_data, xc_data$Place == 10)
place_50 <- subset(xc_data, xc_data$Place == 50)
place_100 <- subset(xc_data, xc_data$Place == 100)
head(place_1)
```

Tenth place:
```{r, echo=FALSE}
head(place_10)
```

One Hundredth place:
```{r, echo=FALSE}
head(place_100)
```

Plotting the times with a line fit and coefficients for 1st place:
```{r, echo=FALSE, fig.align='left'}
plot(place_1$Year, place_1$Time, main = "Scatter Plot of Times for 1st Place", xlab = "Year", ylab = "Time (min)")
abline(lm(place_1$Time ~ place_1$Year))
summary(lm(place_1$Time ~ place_1$Year))$coefficients
```


Plotting the times with a line fit and coefficients for 10th place:
```{r, echo=FALSE, fig.align='left'}
plot(place_10$Year, place_10$Time, main = "Scatter Plot of Times for 10th Place", xlab = "Year", ylab = "Time (min)")
abline(lm(place_10$Time ~ place_10$Year))
summary(lm(place_10$Time ~ place_10$Year))$coefficients
```
Plotting the times with a line fit and coefficients for 50th place:
```{r, echo=FALSE, fig.align='left'}
plot(place_50$Year, place_50$Time, main = "Scatter Plot of Times for 50th Place", xlab = "Year", ylab = "Time (min)")
abline(lm(place_50$Time ~ place_50$Year))
summary(lm(place_50$Time ~ place_50$Year))$coefficients
```
Plotting the times with a line fit and coefficients for 100th place:
```{r, echo=FALSE, fig.align='left'}
plot(place_100$Year, place_100$Time, main = "Scatter Plot of Times for 100th Place", xlab = "Year", ylab = "Time (min)")
abline(lm(place_100$Time ~ place_100$Year))
summary(lm(place_100$Time ~ place_100$Year))$coefficients
```

As you can see, there is noticeable difference between the trends from 1st place to 100th place.  
```{r}
-0.03437327*60
-0.06401809 *60
```
The first place times decreased, on average, of about 2 seconds per year while the 100th place times decreased at a rate of -3.8 seconds a year.  

```{r}
-2.062396*30/60
-3.841085*30/60
```
The girls in 1st place are about a minute faster and the girls in 100th place are almost 2 minutes faster compared to 30 years ago.  

I realize that while a linear correlation works right now, that the actual fit is an exponential decay.  At some point, the improvement in times will flatten because it is impossible for them to get to zero.  However, due to the nature of the data, it is difficult at this time to find that actual fit line.  In 30 more years, when there is more data towards the tail, it would be easier to have a predictive model. 

Now I wanted to break up the data by each grade:
```{r}
data_7 <- subset(xc_data, xc_data$Grade == 7)
data_8 <- subset(xc_data, xc_data$Grade == 8)
data_9 <- subset(xc_data, xc_data$Grade == 9)
data_10 <- subset(xc_data, xc_data$Grade == 10)
data_11 <- subset(xc_data, xc_data$Grade == 11)
data_12 <- subset(xc_data, xc_data$Grade == 12)
head(data_7)
```

Standard deviation of the times per grade:
```{r, echo=FALSE}
sd(data_7$Time) #Test
sd(data_8$Time)
sd(data_9$Time)
sd(data_10$Time)
sd(data_11$Time)
sd(data_12$Time)
```
Average of the times per grade:
```{r, echo=FALSE}
mean(data_7$Time)
mean(data_8$Time)
mean(data_9$Time)
mean(data_10$Time)
mean(data_11$Time)
mean(data_12$Time)
```

Averages of the place per grade:
```{r, echo=FALSE}
mean(data_7$Place)
mean(data_8$Place)
mean(data_9$Place)
mean(data_10$Place)
mean(data_11$Place)
mean(data_12$Place)
```
Seeing this has re-oriented my thoughts on the younger runners a little bit.  I think that some of the 7th graders are filling empty slots on smaller teams so not all of them would finish very high.  

Now I wanted to find all the runners who have made at least 2 trips to the championship race:
```{r, echo=FALSE}
multi_run <- xc_data %>% group_by(xc_data$Name) %>% filter(n()>1)
multi_run
```
The ratio of runners who ran in the championships more than once versus overall per grade:
```{r, echo=FALSE}
sum(multi_run$Grade==7)/sum(xc_data$Grade==7)
sum(multi_run$Grade==8)/sum(xc_data$Grade==8)
sum(multi_run$Grade==9)/sum(xc_data$Grade==9)
sum(multi_run$Grade==10)/sum(xc_data$Grade==10)
sum(multi_run$Grade==11)/sum(xc_data$Grade==11)
sum(multi_run$Grade==12)/sum(xc_data$Grade==12)
```

Then I wanted to find all the girls in top ten over the 30 year period:
```{r, echo=FALSE}
top_10 = subset(multi_run, multi_run$Place<11)
top_10
```

To begin to test my theory of girls not being prodigies when they run fast in 9th grade, I made a data set of all the girls who were in the top 10 in 9th and 12th grade and who had run in the championship more than once:
```{r, echo=FALSE}
data_9_12 <- rbind(subset(top_10, top_10$Grade == 9),subset(top_10, top_10$Grade == 12))
data_9_12
```
To get the real number of girls in this, I needed to find the duplicate names:
```{r, echo=FALSE}
data_9_12[duplicated(data_9_12$`xc_data$Name`), ]
```
As you can see, of the 105 girls who fit in the previous filter, only 14 had been top 10 in 9th and 12th grade.

Now, lets do the same for 11th and 12th grade:
```{r, echo=FALSE}
data_11_12 <- rbind(subset(top_10, top_10$Grade == 11),subset(top_10, top_10$Grade == 12))
data_11_12
```
Finding the duplicate names:
```{r, echo=FALSE}
data_11_12[duplicated(data_11_12$`xc_data$Name`), ]
```
For 11th and 12th grade, 30 out of 103 girls had been in the top 10 more than once.  

The ratios of that would be:
```{r}
14/105
30/103
```

To add a little more data, I wanted to run the same experiment but with the top 20 finishers. 
```{r, echo=FALSE}
top_20 = subset(multi_run, multi_run$Place<21)
top_20
```

The top 20 multi-championship 9th and 12th graders:
```{r, echo=FALSE}
data_9_12_t20 <- rbind(subset(top_20, top_20$Grade == 9),subset(top_20, top_20$Grade == 12))
data_9_12_t20
```
Finding duplicates
```{r, echo=FALSE}
data_9_12_t20[duplicated(data_9_12_t20$`xc_data$Name`), ]
```
For the top 20, 27 of 197 girls had been in the top 20 in 9th and 12th grade.

Again, the top 20 for 11th and 12th grade:
```{r, echo=FALSE}
data_11_12_t20 <- rbind(subset(top_20, top_20$Grade == 11),subset(top_20, top_20$Grade == 12))
data_11_12_t20
```
Finding the duplicate names:
```{r, echo=FALSE}
data_11_12_t20[duplicated(data_11_12_t20$`xc_data$Name`), ]
```
For 11th and 12th grade, 60 out of 188 girls had been in the top 20 more than once.  

The ratios of that would be:
```{r}
27/197
60/180
```
The ratio between the top 10 and top 20 is very similar. 

Finally, I wanted to look at 8th graders to see how many stopped appearing as they got older. This time I am using 8 and 10th grade as my two data sets.

```{r, echo=FALSE}
data_8_10 <- rbind(subset(top_10, top_10$Grade == 8),subset(top_10, top_10$Grade == 10))
data_8_10
```
Filtering duplicate names:
```{r, echo=FALSE}
data_8_10[duplicated(data_8_10$`xc_data$Name`), ]
```
12 out of 72 girls in the top 10 where there in 8th and 10th grade.
```{r}
12/72
```
Again, a very similar ratio to the 9th and 12th grade data. 


# Topics From Class
## RMarkdown
Honestly, I love R Markdown.  It is relatively easy to use and really does a great job of presenting your data/findings in a very organized way.  I still have a lot to learn about R (such as functions which I mentioned above) but I can't see myself ever presenting data in a different way now.  

## Github
I have heard of Github and used it to download some code but I've never actually used it before.  It took some figuring out for me but I eventually got it to work and I really like it.  I can definitely see myself using it more in my schoolwork.  Learning the concepts will also help me with future software jobs where they may use a similar type of system.  

## Regression
I needed to do linear regression to find the line fits and the slope intercept of my data.  I enjoy algebra and have used y=mx+b frequently in my education and career but I had never really done it with large sets of data before.  It was interesting to see how it worked and I like how R does it compared to Excel. If I continue with this topic in future data analysis classes I will see if I can find a exponential decay fit for it.

## Probability
I think finding the probability for girls who were good runners in different grades was actually my favorite part of this entire project. It was also a good opportunity to see aspects to R we didn't learn in class and, ultimately, it was very interesting to see the ratios in my data. Using probabilities also helped me see some gaps in my data that I normally wouldn't have thought of. For instance, there are far fewer 7th and 8th grade data points and that impacted a few of my calculations. 

## Normal Distribution
Coming from my draft, I had a different approach to this.  Listening to feedback from my classmates and seeing what others did with their projects had me rethink of how to show the data distribution.  Instead of showing just one denisty plot of all the times from over the 30 years, I thought it would be better to show two different years in order to demonstrate the change in distribution.

# Conclusion
The data shows that my initial hypothesis, that times have gotten faster and the talent depth has improved, was correct.  I also think there is evidence that fast girls do slow down as they age but I am not sure if there is enough data to have a definite conclusion. Cross country data has always been a passion of mine so it was fun to actually do something with everything I have observed over the last 20 years. While I have always loved playing with data and math, stats has never been my strong suit so doing this helped me a lot in understanding how to use statistics. 

I learned a lot about R and re familiarized myself with some math (notably using natural logarithms when I was trying to fit a curve to the data and ended up not doing).  As stated above, I really wanted to fit a line showing the decay on the scatter plots but I don't think the data was uniform enough for that.  Maybe there is a way to do it with the data I have, if so I would like to learn what that is. Due to that, I don't think a predictive model would be accurate at this time due to it being based on a linear trend and not a logarithmic one. 

One thing I would have liked to do is show more plots and make more data sets.  I think that would tell a better story overall but I felt that was probably too much for this project at this time. 

## Future Improvements
In the future, one thing I'd like to do is make a function that will automatically create the subsets depending on what data you give it. I could do it in Python easily but I am not as familiar with how to write functions in R.

# Sources
I made extended use of [Statology](www.statology.org) for basically every question I had.  

I used this [site](https://jennybc.github.io/2014-05-12-ubc/ubc-r/session2.4_github.html) for help in setting up GitHub for my project since I wasn't able to do it correctly in class.  